# RL_tutorials
This repository contains a 3-part tutorial on basic reinforcement learning algorithms for across-trial and within-trial associative learning, both pavlovian and instrumental.
The first part covers Rescorla-Wagner learning, a classic error-based algorithm for associating stimuli with rewards across trials. 
The second part covers Temporal-Difference learning, which allows for learning temporal predictions within trials and second-order associations.
The third part covers three different model-free RL algorithms for learning valuable actions - actor-critic learning, Q-learning and SARSA.
Each tutorial contains a brief theory overview and questions with starter code, followed by solutions. 
